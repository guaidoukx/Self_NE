import osimport matplotlibimport networkx as nximport numpy as npimport matplotlib.pyplot as pltfrom gensim.models import Word2Vecdef extract_ids_labels(file_name):    ids, labels = [], []    with open(file_name, 'r') as f:        line = f.readline()        while line:            line_splited = line.split()            ids.append(line_splited[0])            labels.append(line_splited[-1])            line = f.readline()    return ids, labels        def load_graph(filename, ids, direction=False):    if direction:        G = nx.DiGraph()        with open(filename, 'r') as f:            line = f.readline()            while line:                line_splited = line.split()                if line_splited[0] in ids and line_splited[1] in ids and line_splited[0] != line_splited[1]:                    G.add_edge(line_splited[0], line_splited[1])                    G[line_splited[0]][line_splited[1]]['weight'] = 1                line = f.readline()    else:        G = nx.Graph()        with open(filename, 'r') as f:            line = f.readline()            while line:                line_splited = line.split()                if line_splited[0] in ids and line_splited[1] in ids and line_splited[0] != line_splited[1]:                    G.add_edge(line_splited[0], line_splited[1])                    G[line_splited[0]][line_splited[1]]['weight'] = 1                    G[line_splited[1]][line_splited[0]]['weight'] = 1                line = f.readline()    return Gdef alias_setup(probs):    """    以图为例，凡是4代表的就是概率类型数的意思    a，记录下面那些部分的概率值（乘以4以后）    b，记录上面部分来自哪个根柱子，用哪根柱子的不来用来补足，使之概率为1    :param probs: 是一个概率的list    """    num = len(probs)    a = np.zeros(num, dtype=np.float32)    b = np.ones(num, dtype=np.int)*-1  # -1 用来表示，本身自己就足够了，和那些用第一根柱子（下标0）的区分开来        small, large = [], []  # 记录乘以4以后的概率 大于1还是小于1 的下标    for i, prob in enumerate(probs):        a[i] = num * prob  # 概率乘以类型数（4）        if a[i] < 1.0:            small.append(i)        else:            large.append(i)                while len(small) > 0 and len(large) > 0:        smaller = small.pop()  # 从大小中各任取一个        larger = large.pop()                a[larger] = a[smaller] + a[larger] - 1.0  # a用来记录本身的概率，而不是加上去的那一部分的概率        b[smaller] = larger  # b用来记录完成每个柱子=1的操作，补自哪个柱子        if a[larger] < 1.0:  # 记录大于1的那个概率，给了别人以后，剩下部分是不是还是大于1（是不是还能继续给别人）            small.append(larger)        else:            large.append(larger)    return a, b        def transition_node_prob(G):    alias_nodes = {}    for node in G.nodes():        probs = [G[node][nbr]['weight'] for nbr in G.neighbors(node)]        sum_probs = sum(probs)        normed_probs = [float(prob)/sum_probs for prob in probs]        alias_nodes[node] = alias_setup(normed_probs)    return alias_nodesdef walk(G, start, walk_length, alias_nodes):    path = [start]    node = path[-1]    neighbours = list(G.neighbors(node))    num = len(neighbours)    while len(path) < walk_length and num > 0:        index = int(np.floor(np.random.rand() * num))        if np.random.rand() > alias_nodes[node][0][index]:            cur = neighbours[alias_nodes[node][1][index]]        else:            cur = neighbours[index]        path.append(cur)        node = cur        neighbours = list(G.neighbors(node))        num = len(neighbours)    return path    def walks(G, start, times, walk_length, alias_nodes):    paths = []    for i in range(times):        paths.append(walk(G, start,walk_length, alias_nodes))    return pathsif __name__ == '__main__':    print(matplotlib.get_backend())        # cora data set    # edge_file_path = 'data/cora/cora.cites'    # content_file_path = 'data/cora/cora.content'    # output_path = 'out/cora/out_paths.txt'    # out_model_path = 'out/cora/model.txt'    # ids, labels = extract_ids_labels(content_file_path)    # wiki data set    # edge_file_path = 'data/wiki/Wiki_edgelist.txt'    # content_file_path = 'data/wiki/wiki_labels.txt'    # output_path = 'out/wiki/out_paths.txt'    # out_model_path = 'out/wiki/model.txt'    # ids, labels = extract_ids_labels(content_file_path)    # karate data set    edge_file_path = 'data/karate/karate.edgelist'    output_path = 'out/karate/out_paths.txt'    out_model_path = 'out/karate/model.txt'    out_graph_path = 'out/karate/graph_save.png'    out_embedding_path = 'out/karate/embed.png'    ids = []    with open(edge_file_path, 'r') as f:        line = f.readline()        while line:            line_splited = line.split()            ids.extend([line_splited[0], line_splited[1]])            line = f.readline()    print(ids)    G = load_graph(edge_file_path, ids=ids, direction=False)    plt.plot()    nx.draw(G, with_labels=True)    plt.savefig(out_graph_path)    plt.show()    alias_nodes = transition_node_prob(G)        paths = []    for node in G.nodes():        paths.extend(walks(G, node, 15, 30, alias_nodes))    with open(output_path, 'w') as f:        for path in paths:            sentence = " ".join(path)            f.write(sentence+'\n')    print("finish writing")        word2vec = Word2Vec(paths, size=2, window=3, iter=50)    vecs = word2vec.wv.vectors    vocabs = word2vec.wv.index2word    X, Y = [], []    for vec in vecs:        X.append(vec[0])        Y.append(vec[1])    print(X, Y)        plt.clf()    plt.scatter(X, Y, data=vocabs)    for i, vocab in enumerate(vocabs):        plt.text(X[i], Y[i], vocab)    plt.savefig(out_embedding_path)    plt.show()    word2vec.save(out_model_path)    print("finish embedding")